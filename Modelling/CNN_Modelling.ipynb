{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "CNN Modelling"
      ],
      "metadata": {
        "id": "bCJDfqhUIKyy"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yeysQ97AIIEk",
        "outputId": "bece56e1-2625-4232-ae60-09699997ac18"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n"
          ]
        }
      ],
      "source": [
        "#Importing the required libraries\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import nltk\n",
        "\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "from nltk.tokenize import word_tokenize\n",
        "\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Embedding, Conv1D, GlobalMaxPooling1D, Dense\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "\n",
        "from keras.wrappers.scikit_learn import KerasClassifier\n",
        "from keras.utils import to_categorical\n",
        "\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "nltk.download('punkt')\n",
        "nltk.download('wordnet')\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "from sklearn.model_selection import RandomizedSearchCV\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.model_selection import RandomizedSearchCV\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, confusion_matrix\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Loading the dataset\n",
        "Preprocessed_df= pd.read_csv('/content/Preprocessed_data_.csv')\n",
        "Preprocessed_df.tail()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 250
        },
        "id": "Nuh30bSuIbxe",
        "outputId": "27347581-a0ae-4aea-d42f-88e4fc1b706b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "       Unnamed: 0                                               text  \\\n",
              "55863       55863   ‪still havent lost row still havent lost leading   \n",
              "55864       55864  ♪… without baby still lonely mind think baby d...   \n",
              "55865       55865            ♫ love quite take whiff hershey stain ♫   \n",
              "55866       55866                   카니발 sound like cannibal carnival   \n",
              "55867       55867  ﾉωﾉ okay senpai owo nuzzles frick write whatev...   \n",
              "\n",
              "                                           original_text listed_emotions  \\\n",
              "55863  ‪Still haven’t lost 3 in a row, Still haven’t ...         neutral   \n",
              "55864  *♪… I'm here without you baby But you're still...    caring, love   \n",
              "55865  ♫ Your love for me Won't be quite the same Whe...            love   \n",
              "55866       카니발 sounds more like cannibal than carnival.            fear   \n",
              "55867  (*ﾉωﾉ) O-okay senpai OWO *Nuzzles* Frick off I...         neutral   \n",
              "\n",
              "       emotion_count    labels  encoded_labels  \n",
              "55863              1   neutral               1  \n",
              "55864              2  positive               2  \n",
              "55865              1  positive               2  \n",
              "55866              1  negative               0  \n",
              "55867              1   neutral               1  "
            ],
            "text/html": [
              "\n",
              "\n",
              "  <div id=\"df-ccebba6f-b729-4121-b295-5623c3a67499\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>text</th>\n",
              "      <th>original_text</th>\n",
              "      <th>listed_emotions</th>\n",
              "      <th>emotion_count</th>\n",
              "      <th>labels</th>\n",
              "      <th>encoded_labels</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>55863</th>\n",
              "      <td>55863</td>\n",
              "      <td>‪still havent lost row still havent lost leading</td>\n",
              "      <td>‪Still haven’t lost 3 in a row, Still haven’t ...</td>\n",
              "      <td>neutral</td>\n",
              "      <td>1</td>\n",
              "      <td>neutral</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>55864</th>\n",
              "      <td>55864</td>\n",
              "      <td>♪… without baby still lonely mind think baby d...</td>\n",
              "      <td>*♪… I'm here without you baby But you're still...</td>\n",
              "      <td>caring, love</td>\n",
              "      <td>2</td>\n",
              "      <td>positive</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>55865</th>\n",
              "      <td>55865</td>\n",
              "      <td>♫ love quite take whiff hershey stain ♫</td>\n",
              "      <td>♫ Your love for me Won't be quite the same Whe...</td>\n",
              "      <td>love</td>\n",
              "      <td>1</td>\n",
              "      <td>positive</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>55866</th>\n",
              "      <td>55866</td>\n",
              "      <td>카니발 sound like cannibal carnival</td>\n",
              "      <td>카니발 sounds more like cannibal than carnival.</td>\n",
              "      <td>fear</td>\n",
              "      <td>1</td>\n",
              "      <td>negative</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>55867</th>\n",
              "      <td>55867</td>\n",
              "      <td>ﾉωﾉ okay senpai owo nuzzles frick write whatev...</td>\n",
              "      <td>(*ﾉωﾉ) O-okay senpai OWO *Nuzzles* Frick off I...</td>\n",
              "      <td>neutral</td>\n",
              "      <td>1</td>\n",
              "      <td>neutral</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-ccebba6f-b729-4121-b295-5623c3a67499')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "\n",
              "\n",
              "\n",
              "    <div id=\"df-9beb1920-f488-4102-8a0b-38eb20cd83ad\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-9beb1920-f488-4102-8a0b-38eb20cd83ad')\"\n",
              "              title=\"Suggest charts.\"\n",
              "              style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "    </div>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "    background-color: #E8F0FE;\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: #1967D2;\n",
              "    height: 32px;\n",
              "    padding: 0 0 0 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: #E2EBFA;\n",
              "    box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: #174EA6;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "    background-color: #3B4455;\n",
              "    fill: #D2E3FC;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart:hover {\n",
              "    background-color: #434B5C;\n",
              "    box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "    filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "    fill: #FFFFFF;\n",
              "  }\n",
              "</style>\n",
              "\n",
              "    <script>\n",
              "      async function quickchart(key) {\n",
              "        const containerElement = document.querySelector('#' + key);\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      }\n",
              "    </script>\n",
              "\n",
              "      <script>\n",
              "\n",
              "function displayQuickchartButton(domScope) {\n",
              "  let quickchartButtonEl =\n",
              "    domScope.querySelector('#df-9beb1920-f488-4102-8a0b-38eb20cd83ad button.colab-df-quickchart');\n",
              "  quickchartButtonEl.style.display =\n",
              "    google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "}\n",
              "\n",
              "        displayQuickchartButton(document);\n",
              "      </script>\n",
              "      <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-ccebba6f-b729-4121-b295-5623c3a67499 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-ccebba6f-b729-4121-b295-5623c3a67499');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Classifying the text and encoded_labels\n",
        "text_label = Preprocessed_df[['text','encoded_labels']]\n",
        "text_label.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "1bK3ZaqfNQTq",
        "outputId": "72537e4a-0352-4b7d-c22d-353bde01cd60"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                          text  encoded_labels\n",
              "0  aa b whole meritocracy gtfo               1\n",
              "1    aaaaaaaaaaaaaahhh imagine               1\n",
              "2         aaaaaaaaaaaaand boop               0\n",
              "3     aaaaaand feeling morning               1\n",
              "4    aaaaaand soccer hopefully               1"
            ],
            "text/html": [
              "\n",
              "\n",
              "  <div id=\"df-3c56b993-1023-44a8-8715-6b62dad4c278\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>encoded_labels</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>aa b whole meritocracy gtfo</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>aaaaaaaaaaaaaahhh imagine</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>aaaaaaaaaaaaand boop</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>aaaaaand feeling morning</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>aaaaaand soccer hopefully</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-3c56b993-1023-44a8-8715-6b62dad4c278')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "\n",
              "\n",
              "\n",
              "    <div id=\"df-8f354ecc-dedd-4091-992c-8951a5a62971\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-8f354ecc-dedd-4091-992c-8951a5a62971')\"\n",
              "              title=\"Suggest charts.\"\n",
              "              style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "    </div>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "    background-color: #E8F0FE;\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: #1967D2;\n",
              "    height: 32px;\n",
              "    padding: 0 0 0 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: #E2EBFA;\n",
              "    box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: #174EA6;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "    background-color: #3B4455;\n",
              "    fill: #D2E3FC;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart:hover {\n",
              "    background-color: #434B5C;\n",
              "    box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "    filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "    fill: #FFFFFF;\n",
              "  }\n",
              "</style>\n",
              "\n",
              "    <script>\n",
              "      async function quickchart(key) {\n",
              "        const containerElement = document.querySelector('#' + key);\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      }\n",
              "    </script>\n",
              "\n",
              "      <script>\n",
              "\n",
              "function displayQuickchartButton(domScope) {\n",
              "  let quickchartButtonEl =\n",
              "    domScope.querySelector('#df-8f354ecc-dedd-4091-992c-8951a5a62971 button.colab-df-quickchart');\n",
              "  quickchartButtonEl.style.display =\n",
              "    google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "}\n",
              "\n",
              "        displayQuickchartButton(document);\n",
              "      </script>\n",
              "      <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-3c56b993-1023-44a8-8715-6b62dad4c278 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-3c56b993-1023-44a8-8715-6b62dad4c278');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "text_label.encoded_labels.unique()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rq7IvqUHOmWV",
        "outputId": "1a642a9f-7a55-4bf0-a915-78373dc3f135"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([1, 0, 2])"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Converting the 'text' column to strings\n",
        "text_label['text'] = text_label['text'].astype(str)\n",
        "\n",
        "#Performing lemmatization on the cleaned text column\n",
        "# Create an instance of WordNetLemmatizer\n",
        "lemmatizer = WordNetLemmatizer()\n",
        "\n",
        "# Function to apply lemmatization to a list of words\n",
        "def apply_lemmatization(word_list):\n",
        "    lemmatized_words = [lemmatizer.lemmatize(word) for word in word_list] #lemmatize each word\n",
        "    lemmatized_text = ' '.join(['[' + lemmatizer.lemmatize(word) + ']' for word in word_list]) #Joining lemmatized words\n",
        "    return lemmatized_text\n",
        "\n",
        "# Create a new column 'lemmatized_column' with the lemmatized text\n",
        "text_label['lemmatized_column'] = text_label['text'].apply(lambda text: apply_lemmatization(word_tokenize(text)))\n",
        "\n",
        "# Print the updated DataFrame\n",
        "print(text_label)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7ArYNBZKO3DR",
        "outputId": "84a8117b-6858-46c4-89ec-f29987aa9adc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                                                    text  encoded_labels  \\\n",
            "0                            aa b whole meritocracy gtfo               1   \n",
            "1                              aaaaaaaaaaaaaahhh imagine               1   \n",
            "2                                   aaaaaaaaaaaaand boop               0   \n",
            "3                               aaaaaand feeling morning               1   \n",
            "4                              aaaaaand soccer hopefully               1   \n",
            "...                                                  ...             ...   \n",
            "55863   ‪still havent lost row still havent lost leading               1   \n",
            "55864  ♪… without baby still lonely mind think baby d...               2   \n",
            "55865            ♫ love quite take whiff hershey stain ♫               2   \n",
            "55866                   카니발 sound like cannibal carnival               0   \n",
            "55867  ﾉωﾉ okay senpai owo nuzzles frick write whatev...               1   \n",
            "\n",
            "                                       lemmatized_column  \n",
            "0                  [aa] [b] [whole] [meritocracy] [gtfo]  \n",
            "1                          [aaaaaaaaaaaaaahhh] [imagine]  \n",
            "2                               [aaaaaaaaaaaaand] [boop]  \n",
            "3                         [aaaaaand] [feeling] [morning]  \n",
            "4                        [aaaaaand] [soccer] [hopefully]  \n",
            "...                                                  ...  \n",
            "55863  [‪still] [havent] [lost] [row] [still] [havent...  \n",
            "55864  [♪…] [without] [baby] [still] [lonely] [mind] ...  \n",
            "55865  [♫] [love] [quite] [take] [whiff] [hershey] [s...  \n",
            "55866         [카니발] [sound] [like] [cannibal] [carnival]  \n",
            "55867  [ﾉωﾉ] [okay] [senpai] [owo] [nuzzles] [frick] ...  \n",
            "\n",
            "[55868 rows x 3 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Creating a new dataframe with the lemmatized column and encoded labels\n",
        "text_label_1  = text_label[['lemmatized_column','encoded_labels']]\n",
        "text_label_1.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "M-cJUueXX0r8",
        "outputId": "69224f76-9710-4029-8590-497734581027"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                       lemmatized_column  encoded_labels\n",
              "0  [aa] [b] [whole] [meritocracy] [gtfo]               1\n",
              "1          [aaaaaaaaaaaaaahhh] [imagine]               1\n",
              "2               [aaaaaaaaaaaaand] [boop]               0\n",
              "3         [aaaaaand] [feeling] [morning]               1\n",
              "4        [aaaaaand] [soccer] [hopefully]               1"
            ],
            "text/html": [
              "\n",
              "\n",
              "  <div id=\"df-ca3f6a0e-0be3-4855-9bda-c899f0a593a3\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>lemmatized_column</th>\n",
              "      <th>encoded_labels</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>[aa] [b] [whole] [meritocracy] [gtfo]</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>[aaaaaaaaaaaaaahhh] [imagine]</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>[aaaaaaaaaaaaand] [boop]</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>[aaaaaand] [feeling] [morning]</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>[aaaaaand] [soccer] [hopefully]</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-ca3f6a0e-0be3-4855-9bda-c899f0a593a3')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "\n",
              "\n",
              "\n",
              "    <div id=\"df-56665e85-43ae-4fe0-b904-c55b0543d275\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-56665e85-43ae-4fe0-b904-c55b0543d275')\"\n",
              "              title=\"Suggest charts.\"\n",
              "              style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "    </div>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "    background-color: #E8F0FE;\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: #1967D2;\n",
              "    height: 32px;\n",
              "    padding: 0 0 0 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: #E2EBFA;\n",
              "    box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: #174EA6;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "    background-color: #3B4455;\n",
              "    fill: #D2E3FC;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart:hover {\n",
              "    background-color: #434B5C;\n",
              "    box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "    filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "    fill: #FFFFFF;\n",
              "  }\n",
              "</style>\n",
              "\n",
              "    <script>\n",
              "      async function quickchart(key) {\n",
              "        const containerElement = document.querySelector('#' + key);\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      }\n",
              "    </script>\n",
              "\n",
              "      <script>\n",
              "\n",
              "function displayQuickchartButton(domScope) {\n",
              "  let quickchartButtonEl =\n",
              "    domScope.querySelector('#df-56665e85-43ae-4fe0-b904-c55b0543d275 button.colab-df-quickchart');\n",
              "  quickchartButtonEl.style.display =\n",
              "    google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "}\n",
              "\n",
              "        displayQuickchartButton(document);\n",
              "      </script>\n",
              "      <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-ca3f6a0e-0be3-4855-9bda-c899f0a593a3 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-ca3f6a0e-0be3-4855-9bda-c899f0a593a3');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Performing tokenisation and train test splits on the lemmatized_column and encoded_labels\n",
        "\n",
        "# Batch Processing Configuration\n",
        "batch_size = 1000\n",
        "\n",
        "# Tokenization and Data Preparation\n",
        "# Tokenization\n",
        "tokenizer = Tokenizer(num_words=5000)  # Limit vocabulary size to the most frequent 5000 words\n",
        "tokenizer.fit_on_texts(text_label_1['lemmatized_column'])  # Fit the tokenizer on lemmatized text\n",
        "word_index = tokenizer.word_index  # Get the word index\n",
        "\n",
        "# Convert text to sequences of integers in batches\n",
        "sequences = []\n",
        "for i in range(0, len(text_label_1), batch_size):\n",
        "    batch_texts = text_label['lemmatized_column'][i:i + batch_size].tolist()\n",
        "    batch_sequences = tokenizer.texts_to_sequences(batch_texts)\n",
        "    sequences.extend(batch_sequences)\n",
        "\n",
        "# Padding sequences to a fixed length\n",
        "max_sequence_length = max(len(sequence) for sequence in sequences)\n",
        "padded_sequences = pad_sequences(sequences, maxlen=max_sequence_length, padding='post')\n",
        "\n",
        "# Convert encoded_labels to numpy array\n",
        "labels = np.array(text_label_1['encoded_labels'])\n",
        "\n",
        "# Train-Test Split\n",
        "X_train, X_test, y_train, y_test = train_test_split(padded_sequences, labels, test_size=0.2, random_state=42)\n",
        "\n",
        "# Print the shapes of train and test sets\n",
        "print(\"X_train shape:\", X_train.shape)\n",
        "print(\"X_test shape:\", X_test.shape)\n",
        "print(\"y_train shape:\", y_train.shape)\n",
        "print(\"y_test shape:\", y_test.shape)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yL9ExT9jTSsX",
        "outputId": "04ebfa56-517d-4ce0-b026-eb8d23a4be5a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "X_train shape: (44694, 25)\n",
            "X_test shape: (11174, 25)\n",
            "y_train shape: (44694,)\n",
            "y_test shape: (11174,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\"\"\"vocab_size = len(word_index) + 1\n",
        "\n",
        "model = Sequential()\n",
        "model.add(Embedding(input_dim=vocab_size, output_dim=embedding_dim, input_length=max_sequence_length))\n",
        "model.add(Conv1D(128, 5, activation='relu'))\n",
        "model.add(GlobalMaxPooling1D())\n",
        "model.add(Dense(4, activation='softmax'))  # Four units for four classes, using softmax activation\n",
        "\n",
        "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "\n",
        "# Convert labels to one-hot encoded format\n",
        "one_hot_labels = to_categorical(labels, num_classes=4)\n",
        "\n",
        "# Train-Test Split\n",
        "X_train, X_test, y_train, y_test = train_test_split(padded_sequences, one_hot_labels, test_size=0.2, random_state=42)\n",
        "\n",
        "# Print the shapes of train and test sets\n",
        "print(\"X_train shape:\", X_train.shape)\n",
        "print(\"X_test shape:\", X_test.shape)\n",
        "print(\"y_train shape:\", y_train.shape)\n",
        "print(\"y_test shape:\", y_test.shape)\n",
        "\n",
        "# Early Stopping\n",
        "early_stopping = EarlyStopping(monitor='val_loss', patience=3, restore_best_weights=True)\n",
        "\n",
        "# Training the model\n",
        "epochs = 10\n",
        "batch_size = 32\n",
        "\n",
        "#Fitting the model\n",
        "model.fit(X_train, one_hot_labels, epochs=epochs, batch_size=batch_size, validation_split=0.1, callbacks=[early_stopping])\n",
        "\n",
        "# Evaluation on test set\n",
        "loss, accuracy = model.evaluate(X_test, y_test)\n",
        "print(\"Test Loss:\", loss)\n",
        "print(\"Test Accuracy:\", accuracy)\n",
        "\"\"\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 140
        },
        "id": "loAgPjJCYnnX",
        "outputId": "c2457f32-79a7-4083-a504-bed2b76342a3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'vocab_size = len(word_index) + 1\\n\\nmodel = Sequential()\\nmodel.add(Embedding(input_dim=vocab_size, output_dim=embedding_dim, input_length=max_sequence_length))\\nmodel.add(Conv1D(128, 5, activation=\\'relu\\'))\\nmodel.add(GlobalMaxPooling1D())\\nmodel.add(Dense(4, activation=\\'softmax\\'))  # Four units for four classes, using softmax activation\\n\\nmodel.compile(loss=\\'categorical_crossentropy\\', optimizer=\\'adam\\', metrics=[\\'accuracy\\'])\\n\\n# Convert labels to one-hot encoded format\\none_hot_labels = to_categorical(labels, num_classes=4)\\n\\n# Train-Test Split\\nX_train, X_test, y_train, y_test = train_test_split(padded_sequences, one_hot_labels, test_size=0.2, random_state=42)\\n\\n# Print the shapes of train and test sets\\nprint(\"X_train shape:\", X_train.shape)\\nprint(\"X_test shape:\", X_test.shape)\\nprint(\"y_train shape:\", y_train.shape)\\nprint(\"y_test shape:\", y_test.shape)\\n\\n# Early Stopping\\nearly_stopping = EarlyStopping(monitor=\\'val_loss\\', patience=3, restore_best_weights=True)\\n\\n# Training the model\\nepochs = 10\\nbatch_size = 32\\n\\n#Fitting the model\\nmodel.fit(X_train, one_hot_labels, epochs=epochs, batch_size=batch_size, validation_split=0.1, callbacks=[early_stopping])\\n\\n# Evaluation on test set\\nloss, accuracy = model.evaluate(X_test, y_test)\\nprint(\"Test Loss:\", loss)\\nprint(\"Test Accuracy:\", accuracy)\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The results obtained are as shown\n",
        "\n",
        "\n",
        "\n",
        "*  X_train shape: (166251, 21)\n",
        "*  X_test shape: (41563, 21)\n",
        "*  y_train shape: (166251, 4)\n",
        "*  y_test shape: (41563, 4)\n",
        "\n",
        "*   Epoch 1/10 val_loss: 1.2233 - val_accuracy: 0.4196\n",
        "*   Epoch 2/10 val_loss: 1.2425 - val_accuracy: 0.3805\n",
        "*   Epoch 3/10 val_loss: 1.2746 - val_accuracy: 0.3959\n",
        "*   Epoch 4/10 val_loss: 1.3088 - val_accuracy: 0.3705\n",
        "\n",
        "\n",
        "Test Loss: 1.2232732772827148\n",
        "Test Accuracy: 0.4179438352584839"
      ],
      "metadata": {
        "id": "ZEuZCKG8rpp8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Padding using a word index length and adding 1 for the padding sequence\n",
        "vocab_size = len(word_index) + 1\n",
        "embedding_dim = 100\n",
        "\n",
        "# Convert labels to one-hot encoded format\n",
        "one_hot_labels = to_categorical(labels, num_classes=4)\n",
        "\n",
        "# Train-Test Split\n",
        "X_train, X_test, y_train, y_test = train_test_split(padded_sequences, one_hot_labels, test_size=0.2, random_state=42)\n",
        "\n",
        "# Define a range of epochs and batch sizes to iterate over\n",
        "epochs_range = range(1, 11)\n",
        "batch_sizes = [32,64,128]\n",
        "\n",
        "#Creating a nested loop to iterate through all the epochs range and batch sizes\n",
        "for batch_size in batch_sizes:\n",
        "    for epochs in epochs_range:\n",
        "        print(f\"Training model with batch size = {batch_size}, epochs = {epochs}\")\n",
        "\n",
        "        model = Sequential()\n",
        "        model.add(Embedding(input_dim=vocab_size, output_dim=embedding_dim, input_length=max_sequence_length))\n",
        "        model.add(Conv1D(128, 5, activation='relu'))\n",
        "        model.add(GlobalMaxPooling1D())\n",
        "        model.add(Dense(4, activation='softmax'))  # Four units for four classes, using softmax activation\n",
        "\n",
        "        model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "\n",
        "        # Early Stopping\n",
        "        early_stopping = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n",
        "\n",
        "        # Fitting the model\n",
        "        model.fit(X_train, y_train, epochs=epochs, batch_size=batch_size, validation_split=0.1, callbacks=[early_stopping])\n",
        "\n",
        "        # Evaluation on test set\n",
        "        loss, accuracy = model.evaluate(X_test, y_test)\n",
        "        print(f\"Test Loss (epochs={epochs}, batch_size={batch_size}):\", loss)\n",
        "        print(f\"Test Accuracy (epochs={epochs}, batch_size={batch_size}):\", accuracy)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "NATFLQ6oS1fC",
        "outputId": "f5e0496a-ea0e-44eb-865f-2e32de09d88c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training model with batch size = 32, epochs = 1\n",
            "1257/1257 [==============================] - 68s 53ms/step - loss: 0.9368 - accuracy: 0.5475 - val_loss: 0.8990 - val_accuracy: 0.5852\n",
            "350/350 [==============================] - 2s 4ms/step - loss: 0.9031 - accuracy: 0.5722\n",
            "Test Loss (epochs=1, batch_size=32): 0.9031403064727783\n",
            "Test Accuracy (epochs=1, batch_size=32): 0.5722212195396423\n",
            "Training model with batch size = 32, epochs = 2\n",
            "Epoch 1/2\n",
            "1257/1257 [==============================] - 70s 55ms/step - loss: 0.9383 - accuracy: 0.5471 - val_loss: 0.8847 - val_accuracy: 0.5886\n",
            "Epoch 2/2\n",
            "1257/1257 [==============================] - 64s 51ms/step - loss: 0.8136 - accuracy: 0.6392 - val_loss: 0.9082 - val_accuracy: 0.5823\n",
            "350/350 [==============================] - 1s 4ms/step - loss: 0.9204 - accuracy: 0.5715\n",
            "Test Loss (epochs=2, batch_size=32): 0.9203854203224182\n",
            "Test Accuracy (epochs=2, batch_size=32): 0.5715053081512451\n",
            "Training model with batch size = 32, epochs = 3\n",
            "Epoch 1/3\n",
            "1257/1257 [==============================] - 66s 52ms/step - loss: 0.9354 - accuracy: 0.5511 - val_loss: 0.8855 - val_accuracy: 0.5823\n",
            "Epoch 2/3\n",
            "1257/1257 [==============================] - 62s 49ms/step - loss: 0.8129 - accuracy: 0.6380 - val_loss: 0.9133 - val_accuracy: 0.5736\n",
            "Epoch 3/3\n",
            "1257/1257 [==============================] - 64s 51ms/step - loss: 0.6525 - accuracy: 0.7347 - val_loss: 1.0122 - val_accuracy: 0.5579\n",
            "350/350 [==============================] - 3s 8ms/step - loss: 1.0364 - accuracy: 0.5476\n",
            "Test Loss (epochs=3, batch_size=32): 1.0364148616790771\n",
            "Test Accuracy (epochs=3, batch_size=32): 0.5476105213165283\n",
            "Training model with batch size = 32, epochs = 4\n",
            "Epoch 1/4\n",
            "1257/1257 [==============================] - 77s 60ms/step - loss: 0.9360 - accuracy: 0.5505 - val_loss: 0.8817 - val_accuracy: 0.5861\n",
            "Epoch 2/4\n",
            "1257/1257 [==============================] - 59s 47ms/step - loss: 0.8113 - accuracy: 0.6388 - val_loss: 0.9111 - val_accuracy: 0.5812\n",
            "Epoch 3/4\n",
            "1257/1257 [==============================] - 61s 48ms/step - loss: 0.6501 - accuracy: 0.7315 - val_loss: 1.0292 - val_accuracy: 0.5441\n",
            "Epoch 4/4\n",
            "1257/1257 [==============================] - 60s 47ms/step - loss: 0.4525 - accuracy: 0.8280 - val_loss: 1.2507 - val_accuracy: 0.5383\n",
            "350/350 [==============================] - 2s 6ms/step - loss: 1.2536 - accuracy: 0.5298\n",
            "Test Loss (epochs=4, batch_size=32): 1.253597617149353\n",
            "Test Accuracy (epochs=4, batch_size=32): 0.5298013091087341\n",
            "Training model with batch size = 32, epochs = 5\n",
            "Epoch 1/5\n",
            "1257/1257 [==============================] - 67s 53ms/step - loss: 0.9371 - accuracy: 0.5466 - val_loss: 0.8863 - val_accuracy: 0.5893\n",
            "Epoch 2/5\n",
            "1257/1257 [==============================] - 62s 50ms/step - loss: 0.8101 - accuracy: 0.6411 - val_loss: 0.9406 - val_accuracy: 0.5667\n",
            "Epoch 3/5\n",
            "1257/1257 [==============================] - 64s 51ms/step - loss: 0.6425 - accuracy: 0.7343 - val_loss: 1.0270 - val_accuracy: 0.5557\n",
            "Epoch 4/5\n",
            "1257/1257 [==============================] - 64s 51ms/step - loss: 0.4444 - accuracy: 0.8294 - val_loss: 1.2340 - val_accuracy: 0.5400\n",
            "Epoch 5/5\n",
            "1257/1257 [==============================] - 64s 51ms/step - loss: 0.2953 - accuracy: 0.8934 - val_loss: 1.5028 - val_accuracy: 0.5324\n",
            "350/350 [==============================] - 2s 6ms/step - loss: 1.5534 - accuracy: 0.5189\n",
            "Test Loss (epochs=5, batch_size=32): 1.553364872932434\n",
            "Test Accuracy (epochs=5, batch_size=32): 0.5188831090927124\n",
            "Training model with batch size = 32, epochs = 6\n",
            "Epoch 1/6\n",
            "1257/1257 [==============================] - 75s 59ms/step - loss: 0.9376 - accuracy: 0.5465 - val_loss: 0.8832 - val_accuracy: 0.5890\n",
            "Epoch 2/6\n",
            "1257/1257 [==============================] - 68s 54ms/step - loss: 0.8093 - accuracy: 0.6394 - val_loss: 0.9129 - val_accuracy: 0.5743\n",
            "Epoch 3/6\n",
            "1257/1257 [==============================] - 71s 56ms/step - loss: 0.6400 - accuracy: 0.7360 - val_loss: 1.0398 - val_accuracy: 0.5553\n",
            "Epoch 4/6\n",
            "1257/1257 [==============================] - 67s 54ms/step - loss: 0.4399 - accuracy: 0.8348 - val_loss: 1.2515 - val_accuracy: 0.5257\n",
            "Epoch 5/6\n",
            "1257/1257 [==============================] - 68s 54ms/step - loss: 0.2880 - accuracy: 0.8968 - val_loss: 1.5262 - val_accuracy: 0.5192\n",
            "Epoch 6/6\n",
            "1257/1257 [==============================] - 68s 54ms/step - loss: 0.1966 - accuracy: 0.9302 - val_loss: 1.8083 - val_accuracy: 0.5170\n",
            "350/350 [==============================] - 2s 5ms/step - loss: 1.8424 - accuracy: 0.5147\n",
            "Test Loss (epochs=6, batch_size=32): 1.842362642288208\n",
            "Test Accuracy (epochs=6, batch_size=32): 0.5146769285202026\n",
            "Training model with batch size = 32, epochs = 7\n",
            "Epoch 1/7\n",
            "1257/1257 [==============================] - 68s 54ms/step - loss: 0.9369 - accuracy: 0.5475 - val_loss: 0.8896 - val_accuracy: 0.5895\n",
            "Epoch 2/7\n",
            "1257/1257 [==============================] - 67s 53ms/step - loss: 0.8111 - accuracy: 0.6386 - val_loss: 0.9022 - val_accuracy: 0.5855\n",
            "Epoch 3/7\n",
            "1257/1257 [==============================] - 66s 52ms/step - loss: 0.6436 - accuracy: 0.7366 - val_loss: 1.0331 - val_accuracy: 0.5620\n",
            "Epoch 4/7\n",
            "1257/1257 [==============================] - 67s 53ms/step - loss: 0.4474 - accuracy: 0.8316 - val_loss: 1.2420 - val_accuracy: 0.5376\n",
            "Epoch 5/7\n",
            "1257/1257 [==============================] - 65s 52ms/step - loss: 0.2988 - accuracy: 0.8928 - val_loss: 1.4792 - val_accuracy: 0.5309\n",
            "Epoch 6/7\n",
            "1257/1257 [==============================] - 65s 52ms/step - loss: 0.2075 - accuracy: 0.9274 - val_loss: 1.7893 - val_accuracy: 0.5309\n",
            "Epoch 7/7\n",
            "1257/1257 [==============================] - 69s 55ms/step - loss: 0.1511 - accuracy: 0.9466 - val_loss: 2.0688 - val_accuracy: 0.5197\n",
            "350/350 [==============================] - 2s 4ms/step - loss: 2.1436 - accuracy: 0.5101\n",
            "Test Loss (epochs=7, batch_size=32): 2.1436002254486084\n",
            "Test Accuracy (epochs=7, batch_size=32): 0.5101127624511719\n",
            "Training model with batch size = 32, epochs = 8\n",
            "Epoch 1/8\n",
            "1257/1257 [==============================] - 73s 58ms/step - loss: 0.9360 - accuracy: 0.5502 - val_loss: 0.8814 - val_accuracy: 0.5870\n",
            "Epoch 2/8\n",
            "1257/1257 [==============================] - 73s 58ms/step - loss: 0.8079 - accuracy: 0.6408 - val_loss: 0.9342 - val_accuracy: 0.5694\n",
            "Epoch 3/8\n",
            "1257/1257 [==============================] - 72s 57ms/step - loss: 0.6385 - accuracy: 0.7373 - val_loss: 1.0517 - val_accuracy: 0.5488\n",
            "Epoch 4/8\n",
            "1257/1257 [==============================] - 70s 56ms/step - loss: 0.4383 - accuracy: 0.8314 - val_loss: 1.2564 - val_accuracy: 0.5367\n",
            "Epoch 5/8\n",
            "1257/1257 [==============================] - 72s 57ms/step - loss: 0.2877 - accuracy: 0.8973 - val_loss: 1.5390 - val_accuracy: 0.5177\n",
            "Epoch 6/8\n",
            "1257/1257 [==============================] - 69s 55ms/step - loss: 0.1970 - accuracy: 0.9304 - val_loss: 1.8411 - val_accuracy: 0.5103\n",
            "Epoch 7/8\n",
            "1257/1257 [==============================] - 71s 56ms/step - loss: 0.1441 - accuracy: 0.9493 - val_loss: 2.1749 - val_accuracy: 0.5172\n",
            "Epoch 8/8\n",
            "1257/1257 [==============================] - 78s 62ms/step - loss: 0.1114 - accuracy: 0.9610 - val_loss: 2.4757 - val_accuracy: 0.5085\n",
            "350/350 [==============================] - 2s 5ms/step - loss: 2.4939 - accuracy: 0.5037\n",
            "Test Loss (epochs=8, batch_size=32): 2.4939143657684326\n",
            "Test Accuracy (epochs=8, batch_size=32): 0.503669261932373\n",
            "Training model with batch size = 32, epochs = 9\n",
            "Epoch 1/9\n",
            "1257/1257 [==============================] - 69s 54ms/step - loss: 0.9345 - accuracy: 0.5476 - val_loss: 0.8794 - val_accuracy: 0.5919\n",
            "Epoch 2/9\n",
            "1257/1257 [==============================] - 68s 54ms/step - loss: 0.8129 - accuracy: 0.6396 - val_loss: 0.9216 - val_accuracy: 0.5756\n",
            "Epoch 3/9\n",
            "1257/1257 [==============================] - 66s 53ms/step - loss: 0.6533 - accuracy: 0.7282 - val_loss: 1.0216 - val_accuracy: 0.5570\n",
            "Epoch 4/9\n",
            "1257/1257 [==============================] - 68s 54ms/step - loss: 0.4558 - accuracy: 0.8261 - val_loss: 1.2098 - val_accuracy: 0.5387\n",
            "Epoch 5/9\n",
            "1257/1257 [==============================] - 68s 54ms/step - loss: 0.3024 - accuracy: 0.8914 - val_loss: 1.5093 - val_accuracy: 0.5280\n",
            "Epoch 6/9\n",
            "1257/1257 [==============================] - 66s 53ms/step - loss: 0.2061 - accuracy: 0.9275 - val_loss: 1.7629 - val_accuracy: 0.5092\n",
            "Epoch 7/9\n",
            "1257/1257 [==============================] - 67s 53ms/step - loss: 0.1494 - accuracy: 0.9464 - val_loss: 2.0792 - val_accuracy: 0.5183\n",
            "Epoch 8/9\n",
            "1257/1257 [==============================] - 68s 54ms/step - loss: 0.1146 - accuracy: 0.9591 - val_loss: 2.3832 - val_accuracy: 0.5154\n",
            "Epoch 9/9\n",
            "1257/1257 [==============================] - 67s 53ms/step - loss: 0.0927 - accuracy: 0.9667 - val_loss: 2.6693 - val_accuracy: 0.5154\n",
            "350/350 [==============================] - 2s 5ms/step - loss: 2.7321 - accuracy: 0.5021\n",
            "Test Loss (epochs=9, batch_size=32): 2.7321078777313232\n",
            "Test Accuracy (epochs=9, batch_size=32): 0.5021478533744812\n",
            "Training model with batch size = 32, epochs = 10\n",
            "Epoch 1/10\n",
            "1257/1257 [==============================] - 68s 53ms/step - loss: 0.9362 - accuracy: 0.5510 - val_loss: 0.8799 - val_accuracy: 0.5866\n",
            "Epoch 2/10\n",
            "1257/1257 [==============================] - 68s 54ms/step - loss: 0.8114 - accuracy: 0.6402 - val_loss: 0.9035 - val_accuracy: 0.5785\n",
            "Epoch 3/10\n",
            "1257/1257 [==============================] - 66s 52ms/step - loss: 0.6489 - accuracy: 0.7306 - val_loss: 1.0154 - val_accuracy: 0.5593\n",
            "Epoch 4/10\n",
            "1257/1257 [==============================] - 68s 54ms/step - loss: 0.4541 - accuracy: 0.8248 - val_loss: 1.2389 - val_accuracy: 0.5430\n",
            "Epoch 5/10\n",
            "1257/1257 [==============================] - 68s 54ms/step - loss: 0.3028 - accuracy: 0.8913 - val_loss: 1.5109 - val_accuracy: 0.5242\n",
            "Epoch 6/10\n",
            "1257/1257 [==============================] - 68s 54ms/step - loss: 0.2091 - accuracy: 0.9267 - val_loss: 1.7853 - val_accuracy: 0.5181\n",
            "Epoch 7/10\n",
            "1257/1257 [==============================] - 69s 55ms/step - loss: 0.1528 - accuracy: 0.9460 - val_loss: 2.0824 - val_accuracy: 0.5125\n",
            "Epoch 8/10\n",
            "1257/1257 [==============================] - 67s 53ms/step - loss: 0.1157 - accuracy: 0.9589 - val_loss: 2.4115 - val_accuracy: 0.5179\n",
            "Epoch 9/10\n",
            "1257/1257 [==============================] - 68s 54ms/step - loss: 0.0936 - accuracy: 0.9664 - val_loss: 2.7115 - val_accuracy: 0.4980\n",
            "Epoch 10/10\n",
            "1257/1257 [==============================] - 68s 54ms/step - loss: 0.0796 - accuracy: 0.9701 - val_loss: 2.9806 - val_accuracy: 0.5143\n",
            "350/350 [==============================] - 2s 6ms/step - loss: 2.9398 - accuracy: 0.5089\n",
            "Test Loss (epochs=10, batch_size=32): 2.9398131370544434\n",
            "Test Accuracy (epochs=10, batch_size=32): 0.5088598728179932\n",
            "Training model with batch size = 64, epochs = 1\n",
            "629/629 [==============================] - 42s 65ms/step - loss: 0.9480 - accuracy: 0.5405 - val_loss: 0.8857 - val_accuracy: 0.5928\n",
            "350/350 [==============================] - 2s 4ms/step - loss: 0.8905 - accuracy: 0.5820\n",
            "Test Loss (epochs=1, batch_size=64): 0.8904976844787598\n",
            "Test Accuracy (epochs=1, batch_size=64): 0.5819759964942932\n",
            "Training model with batch size = 64, epochs = 2\n",
            "Epoch 1/2\n",
            "629/629 [==============================] - 42s 65ms/step - loss: 0.9474 - accuracy: 0.5401 - val_loss: 0.8835 - val_accuracy: 0.5855\n",
            "Epoch 2/2\n",
            "629/629 [==============================] - 38s 61ms/step - loss: 0.8243 - accuracy: 0.6311 - val_loss: 0.8993 - val_accuracy: 0.5785\n",
            "350/350 [==============================] - 3s 7ms/step - loss: 0.9068 - accuracy: 0.5758\n",
            "Test Loss (epochs=2, batch_size=64): 0.9067698121070862\n",
            "Test Accuracy (epochs=2, batch_size=64): 0.5758009552955627\n",
            "Training model with batch size = 64, epochs = 3\n",
            "Epoch 1/3\n",
            "629/629 [==============================] - 42s 65ms/step - loss: 0.9469 - accuracy: 0.5428 - val_loss: 0.8815 - val_accuracy: 0.5926\n",
            "Epoch 2/3\n",
            "629/629 [==============================] - 41s 65ms/step - loss: 0.8221 - accuracy: 0.6343 - val_loss: 0.8979 - val_accuracy: 0.5843\n",
            "Epoch 3/3\n",
            "629/629 [==============================] - 40s 64ms/step - loss: 0.6866 - accuracy: 0.7122 - val_loss: 0.9792 - val_accuracy: 0.5579\n",
            "350/350 [==============================] - 2s 5ms/step - loss: 0.9848 - accuracy: 0.5571\n",
            "Test Loss (epochs=3, batch_size=64): 0.9847662448883057\n",
            "Test Accuracy (epochs=3, batch_size=64): 0.5570968389511108\n",
            "Training model with batch size = 64, epochs = 4\n",
            "Epoch 1/4\n",
            "629/629 [==============================] - 42s 66ms/step - loss: 0.9488 - accuracy: 0.5399 - val_loss: 0.8820 - val_accuracy: 0.5879\n",
            "Epoch 2/4\n",
            "629/629 [==============================] - 40s 63ms/step - loss: 0.8213 - accuracy: 0.6345 - val_loss: 0.8932 - val_accuracy: 0.5864\n",
            "Epoch 3/4\n",
            "629/629 [==============================] - 40s 63ms/step - loss: 0.6865 - accuracy: 0.7129 - val_loss: 0.9845 - val_accuracy: 0.5577\n",
            "Epoch 4/4\n",
            "629/629 [==============================] - 41s 65ms/step - loss: 0.5087 - accuracy: 0.8044 - val_loss: 1.1611 - val_accuracy: 0.5479\n",
            "350/350 [==============================] - 2s 5ms/step - loss: 1.1800 - accuracy: 0.5382\n",
            "Test Loss (epochs=4, batch_size=64): 1.180033802986145\n",
            "Test Accuracy (epochs=4, batch_size=64): 0.5382137298583984\n",
            "Training model with batch size = 64, epochs = 5\n",
            "Epoch 1/5\n",
            "629/629 [==============================] - 42s 66ms/step - loss: 0.9459 - accuracy: 0.5413 - val_loss: 0.8826 - val_accuracy: 0.5817\n",
            "Epoch 2/5\n",
            "629/629 [==============================] - 41s 65ms/step - loss: 0.8205 - accuracy: 0.6328 - val_loss: 0.9090 - val_accuracy: 0.5846\n",
            "Epoch 3/5\n",
            "629/629 [==============================] - 42s 66ms/step - loss: 0.6877 - accuracy: 0.7131 - val_loss: 0.9767 - val_accuracy: 0.5635\n",
            "Epoch 4/5\n",
            "629/629 [==============================] - 42s 66ms/step - loss: 0.5200 - accuracy: 0.7982 - val_loss: 1.1334 - val_accuracy: 0.5438\n",
            "Epoch 5/5\n",
            "629/629 [==============================] - 42s 67ms/step - loss: 0.3695 - accuracy: 0.8670 - val_loss: 1.3398 - val_accuracy: 0.5365\n",
            "350/350 [==============================] - 2s 5ms/step - loss: 1.3667 - accuracy: 0.5313\n",
            "Test Loss (epochs=5, batch_size=64): 1.3667157888412476\n",
            "Test Accuracy (epochs=5, batch_size=64): 0.531322717666626\n",
            "Training model with batch size = 64, epochs = 6\n",
            "Epoch 1/6\n",
            "629/629 [==============================] - 42s 66ms/step - loss: 0.9496 - accuracy: 0.5390 - val_loss: 0.8858 - val_accuracy: 0.5881\n",
            "Epoch 2/6\n",
            "629/629 [==============================] - 39s 62ms/step - loss: 0.8220 - accuracy: 0.6318 - val_loss: 0.9143 - val_accuracy: 0.5709\n",
            "Epoch 3/6\n",
            "629/629 [==============================] - 41s 66ms/step - loss: 0.6861 - accuracy: 0.7136 - val_loss: 0.9697 - val_accuracy: 0.5658\n",
            "Epoch 4/6\n",
            "629/629 [==============================] - 43s 68ms/step - loss: 0.5092 - accuracy: 0.8010 - val_loss: 1.1264 - val_accuracy: 0.5474\n",
            "Epoch 5/6\n",
            "629/629 [==============================] - 42s 67ms/step - loss: 0.3569 - accuracy: 0.8701 - val_loss: 1.3656 - val_accuracy: 0.5253\n",
            "Epoch 6/6\n",
            "629/629 [==============================] - 40s 64ms/step - loss: 0.2505 - accuracy: 0.9115 - val_loss: 1.6142 - val_accuracy: 0.5219\n",
            "350/350 [==============================] - 2s 5ms/step - loss: 1.6318 - accuracy: 0.5220\n",
            "Test Loss (epochs=6, batch_size=64): 1.6317788362503052\n",
            "Test Accuracy (epochs=6, batch_size=64): 0.522015392780304\n",
            "Training model with batch size = 64, epochs = 7\n",
            "Epoch 1/7\n",
            "629/629 [==============================] - 41s 64ms/step - loss: 0.9483 - accuracy: 0.5402 - val_loss: 0.8927 - val_accuracy: 0.5814\n",
            "Epoch 2/7\n",
            "629/629 [==============================] - 40s 64ms/step - loss: 0.8234 - accuracy: 0.6322 - val_loss: 0.8987 - val_accuracy: 0.5870\n",
            "Epoch 3/7\n",
            "629/629 [==============================] - 40s 63ms/step - loss: 0.6920 - accuracy: 0.7120 - val_loss: 0.9855 - val_accuracy: 0.5626\n",
            "Epoch 4/7\n",
            "629/629 [==============================] - 41s 64ms/step - loss: 0.5208 - accuracy: 0.7959 - val_loss: 1.1462 - val_accuracy: 0.5470\n",
            "Epoch 5/7\n",
            "629/629 [==============================] - 40s 64ms/step - loss: 0.3675 - accuracy: 0.8674 - val_loss: 1.3686 - val_accuracy: 0.5313\n",
            "Epoch 6/7\n",
            "629/629 [==============================] - 41s 65ms/step - loss: 0.2602 - accuracy: 0.9085 - val_loss: 1.6245 - val_accuracy: 0.5286\n",
            "Epoch 7/7\n",
            "629/629 [==============================] - 38s 61ms/step - loss: 0.1891 - accuracy: 0.9349 - val_loss: 1.8902 - val_accuracy: 0.5186\n",
            "350/350 [==============================] - 2s 5ms/step - loss: 1.8804 - accuracy: 0.5139\n",
            "Test Loss (epochs=7, batch_size=64): 1.880371332168579\n",
            "Test Accuracy (epochs=7, batch_size=64): 0.5138714909553528\n",
            "Training model with batch size = 64, epochs = 8\n",
            "Epoch 1/8\n",
            "629/629 [==============================] - 41s 64ms/step - loss: 0.9473 - accuracy: 0.5389 - val_loss: 0.8885 - val_accuracy: 0.5848\n",
            "Epoch 2/8\n",
            "629/629 [==============================] - 38s 61ms/step - loss: 0.8211 - accuracy: 0.6317 - val_loss: 0.9033 - val_accuracy: 0.5743\n",
            "Epoch 3/8\n",
            "629/629 [==============================] - 39s 61ms/step - loss: 0.6847 - accuracy: 0.7114 - val_loss: 0.9861 - val_accuracy: 0.5577\n",
            "Epoch 4/8\n",
            "629/629 [==============================] - 38s 60ms/step - loss: 0.5061 - accuracy: 0.8059 - val_loss: 1.1541 - val_accuracy: 0.5360\n",
            "Epoch 5/8\n",
            "629/629 [==============================] - 38s 60ms/step - loss: 0.3521 - accuracy: 0.8723 - val_loss: 1.3824 - val_accuracy: 0.5242\n",
            "Epoch 6/8\n",
            "629/629 [==============================] - 39s 62ms/step - loss: 0.2479 - accuracy: 0.9132 - val_loss: 1.6226 - val_accuracy: 0.5206\n",
            "Epoch 7/8\n",
            "629/629 [==============================] - 37s 59ms/step - loss: 0.1810 - accuracy: 0.9375 - val_loss: 1.8596 - val_accuracy: 0.5110\n",
            "Epoch 8/8\n",
            "629/629 [==============================] - 39s 61ms/step - loss: 0.1390 - accuracy: 0.9531 - val_loss: 2.1048 - val_accuracy: 0.5174\n",
            "350/350 [==============================] - 2s 4ms/step - loss: 2.1203 - accuracy: 0.5177\n",
            "Test Loss (epochs=8, batch_size=64): 2.1203198432922363\n",
            "Test Accuracy (epochs=8, batch_size=64): 0.5177196860313416\n",
            "Training model with batch size = 64, epochs = 9\n",
            "Epoch 1/9\n",
            "629/629 [==============================] - 43s 67ms/step - loss: 0.9514 - accuracy: 0.5356 - val_loss: 0.8886 - val_accuracy: 0.5803\n",
            "Epoch 2/9\n",
            "629/629 [==============================] - 39s 62ms/step - loss: 0.8230 - accuracy: 0.6331 - val_loss: 0.8993 - val_accuracy: 0.5774\n",
            "Epoch 3/9\n",
            "629/629 [==============================] - 39s 62ms/step - loss: 0.6904 - accuracy: 0.7098 - val_loss: 0.9700 - val_accuracy: 0.5644\n",
            "Epoch 4/9\n",
            "629/629 [==============================] - 40s 63ms/step - loss: 0.5211 - accuracy: 0.7991 - val_loss: 1.1459 - val_accuracy: 0.5416\n",
            "Epoch 5/9\n",
            "629/629 [==============================] - 40s 63ms/step - loss: 0.3704 - accuracy: 0.8651 - val_loss: 1.3701 - val_accuracy: 0.5345\n",
            "Epoch 6/9\n",
            "629/629 [==============================] - 39s 62ms/step - loss: 0.2634 - accuracy: 0.9071 - val_loss: 1.5872 - val_accuracy: 0.5275\n",
            "Epoch 7/9\n",
            "629/629 [==============================] - 39s 62ms/step - loss: 0.1924 - accuracy: 0.9343 - val_loss: 1.8266 - val_accuracy: 0.5174\n",
            "Epoch 8/9\n",
            "629/629 [==============================] - 39s 62ms/step - loss: 0.1477 - accuracy: 0.9492 - val_loss: 2.0608 - val_accuracy: 0.5116\n",
            "Epoch 9/9\n",
            "629/629 [==============================] - 38s 60ms/step - loss: 0.1186 - accuracy: 0.9598 - val_loss: 2.3445 - val_accuracy: 0.5067\n",
            "350/350 [==============================] - 2s 5ms/step - loss: 2.3494 - accuracy: 0.5051\n",
            "Test Loss (epochs=9, batch_size=64): 2.3494277000427246\n",
            "Test Accuracy (epochs=9, batch_size=64): 0.5051011443138123\n",
            "Training model with batch size = 64, epochs = 10\n",
            "Epoch 1/10\n",
            "629/629 [==============================] - 44s 69ms/step - loss: 0.9471 - accuracy: 0.5392 - val_loss: 0.9268 - val_accuracy: 0.5609\n",
            "Epoch 2/10\n",
            "629/629 [==============================] - 41s 66ms/step - loss: 0.8237 - accuracy: 0.6325 - val_loss: 0.9107 - val_accuracy: 0.5734\n",
            "Epoch 3/10\n",
            "629/629 [==============================] - 40s 63ms/step - loss: 0.6945 - accuracy: 0.7084 - val_loss: 0.9787 - val_accuracy: 0.5622\n",
            "Epoch 4/10\n",
            "629/629 [==============================] - 41s 65ms/step - loss: 0.5294 - accuracy: 0.7942 - val_loss: 1.1318 - val_accuracy: 0.5535\n",
            "Epoch 5/10\n",
            "629/629 [==============================] - 41s 66ms/step - loss: 0.3764 - accuracy: 0.8640 - val_loss: 1.3323 - val_accuracy: 0.5304\n",
            "Epoch 6/10\n",
            "629/629 [==============================] - 42s 66ms/step - loss: 0.2651 - accuracy: 0.9065 - val_loss: 1.6053 - val_accuracy: 0.5293\n",
            "Epoch 7/10\n",
            "629/629 [==============================] - 41s 65ms/step - loss: 0.1930 - accuracy: 0.9339 - val_loss: 1.8319 - val_accuracy: 0.5219\n",
            "Epoch 8/10\n",
            "629/629 [==============================] - 40s 64ms/step - loss: 0.1469 - accuracy: 0.9495 - val_loss: 2.0970 - val_accuracy: 0.5177\n",
            "Epoch 9/10\n",
            "629/629 [==============================] - 40s 64ms/step - loss: 0.1158 - accuracy: 0.9605 - val_loss: 2.3198 - val_accuracy: 0.5045\n",
            "Epoch 10/10\n",
            "629/629 [==============================] - 41s 65ms/step - loss: 0.0942 - accuracy: 0.9678 - val_loss: 2.5957 - val_accuracy: 0.5105\n",
            "350/350 [==============================] - 2s 5ms/step - loss: 2.5752 - accuracy: 0.5139\n",
            "Test Loss (epochs=10, batch_size=64): 2.57523775100708\n",
            "Test Accuracy (epochs=10, batch_size=64): 0.5138714909553528\n",
            "Training model with batch size = 128, epochs = 1\n",
            "315/315 [==============================] - 28s 86ms/step - loss: 0.9718 - accuracy: 0.5223 - val_loss: 0.8840 - val_accuracy: 0.5861\n",
            "350/350 [==============================] - 2s 5ms/step - loss: 0.8903 - accuracy: 0.5792\n",
            "Test Loss (epochs=1, batch_size=128): 0.8903059959411621\n",
            "Test Accuracy (epochs=1, batch_size=128): 0.5792016983032227\n",
            "Training model with batch size = 128, epochs = 2\n",
            "Epoch 1/2\n",
            "315/315 [==============================] - 26s 81ms/step - loss: 0.9773 - accuracy: 0.5190 - val_loss: 0.8916 - val_accuracy: 0.5729\n",
            "Epoch 2/2\n",
            "315/315 [==============================] - 24s 77ms/step - loss: 0.8375 - accuracy: 0.6225 - val_loss: 0.8924 - val_accuracy: 0.5846\n",
            "350/350 [==============================] - 2s 6ms/step - loss: 0.9002 - accuracy: 0.5785\n",
            "Test Loss (epochs=2, batch_size=128): 0.9001678824424744\n",
            "Test Accuracy (epochs=2, batch_size=128): 0.5784857869148254\n",
            "Training model with batch size = 128, epochs = 3\n",
            "Epoch 1/3\n",
            "315/315 [==============================] - 26s 78ms/step - loss: 0.9684 - accuracy: 0.5279 - val_loss: 0.8889 - val_accuracy: 0.5790\n",
            "Epoch 2/3\n",
            "315/315 [==============================] - 26s 82ms/step - loss: 0.8324 - accuracy: 0.6254 - val_loss: 0.9135 - val_accuracy: 0.5761\n",
            "Epoch 3/3\n",
            "315/315 [==============================] - 25s 80ms/step - loss: 0.7344 - accuracy: 0.6881 - val_loss: 0.9566 - val_accuracy: 0.5631\n",
            "350/350 [==============================] - 2s 5ms/step - loss: 0.9563 - accuracy: 0.5639\n",
            "Test Loss (epochs=3, batch_size=128): 0.9562728404998779\n",
            "Test Accuracy (epochs=3, batch_size=128): 0.5638983249664307\n",
            "Training model with batch size = 128, epochs = 4\n",
            "Epoch 1/4\n",
            "315/315 [==============================] - 26s 80ms/step - loss: 0.9716 - accuracy: 0.5252 - val_loss: 0.8853 - val_accuracy: 0.5879\n",
            "Epoch 2/4\n",
            "315/315 [==============================] - 26s 84ms/step - loss: 0.8344 - accuracy: 0.6237 - val_loss: 0.8967 - val_accuracy: 0.5884\n",
            "Epoch 3/4\n",
            "315/315 [==============================] - 26s 83ms/step - loss: 0.7353 - accuracy: 0.6858 - val_loss: 0.9405 - val_accuracy: 0.5723\n",
            "Epoch 4/4\n",
            "315/315 [==============================] - 26s 84ms/step - loss: 0.6037 - accuracy: 0.7608 - val_loss: 1.0425 - val_accuracy: 0.5488\n",
            "350/350 [==============================] - 2s 5ms/step - loss: 1.0488 - accuracy: 0.5461\n",
            "Test Loss (epochs=4, batch_size=128): 1.0488049983978271\n",
            "Test Accuracy (epochs=4, batch_size=128): 0.5460891127586365\n",
            "Training model with batch size = 128, epochs = 5\n",
            "Epoch 1/5\n",
            "315/315 [==============================] - 26s 79ms/step - loss: 0.9669 - accuracy: 0.5278 - val_loss: 0.8915 - val_accuracy: 0.5763\n",
            "Epoch 2/5\n",
            "315/315 [==============================] - 23s 74ms/step - loss: 0.8336 - accuracy: 0.6277 - val_loss: 0.8965 - val_accuracy: 0.5814\n",
            "Epoch 3/5\n",
            "315/315 [==============================] - 24s 77ms/step - loss: 0.7334 - accuracy: 0.6869 - val_loss: 0.9474 - val_accuracy: 0.5658\n",
            "Epoch 4/5\n",
            "315/315 [==============================] - 24s 77ms/step - loss: 0.6007 - accuracy: 0.7619 - val_loss: 1.0548 - val_accuracy: 0.5544\n",
            "Epoch 5/5\n",
            "315/315 [==============================] - 23s 75ms/step - loss: 0.4661 - accuracy: 0.8256 - val_loss: 1.1965 - val_accuracy: 0.5353\n",
            "350/350 [==============================] - 2s 5ms/step - loss: 1.2007 - accuracy: 0.5364\n",
            "Test Loss (epochs=5, batch_size=128): 1.20068359375\n",
            "Test Accuracy (epochs=5, batch_size=128): 0.5364238619804382\n",
            "Training model with batch size = 128, epochs = 6\n",
            "Epoch 1/6\n",
            "315/315 [==============================] - 26s 79ms/step - loss: 0.9678 - accuracy: 0.5270 - val_loss: 0.8833 - val_accuracy: 0.5899\n",
            "Epoch 2/6\n",
            "315/315 [==============================] - 26s 81ms/step - loss: 0.8324 - accuracy: 0.6277 - val_loss: 0.8988 - val_accuracy: 0.5756\n",
            "Epoch 3/6\n",
            "315/315 [==============================] - 24s 77ms/step - loss: 0.7322 - accuracy: 0.6872 - val_loss: 0.9495 - val_accuracy: 0.5604\n",
            "Epoch 4/6\n",
            "315/315 [==============================] - 25s 78ms/step - loss: 0.5968 - accuracy: 0.7626 - val_loss: 1.0592 - val_accuracy: 0.5544\n",
            "Epoch 5/6\n",
            "315/315 [==============================] - 25s 78ms/step - loss: 0.4565 - accuracy: 0.8291 - val_loss: 1.1848 - val_accuracy: 0.5345\n",
            "Epoch 6/6\n",
            "315/315 [==============================] - 24s 75ms/step - loss: 0.3440 - accuracy: 0.8783 - val_loss: 1.3681 - val_accuracy: 0.5327\n",
            "350/350 [==============================] - 2s 5ms/step - loss: 1.3939 - accuracy: 0.5260\n",
            "Test Loss (epochs=6, batch_size=128): 1.393876075744629\n",
            "Test Accuracy (epochs=6, batch_size=128): 0.5260425806045532\n",
            "Training model with batch size = 128, epochs = 7\n",
            "Epoch 1/7\n",
            "315/315 [==============================] - 26s 79ms/step - loss: 0.9729 - accuracy: 0.5214 - val_loss: 0.8887 - val_accuracy: 0.5794\n",
            "Epoch 2/7\n",
            "315/315 [==============================] - 23s 73ms/step - loss: 0.8349 - accuracy: 0.6264 - val_loss: 0.8946 - val_accuracy: 0.5872\n",
            "Epoch 3/7\n",
            "315/315 [==============================] - 24s 78ms/step - loss: 0.7341 - accuracy: 0.6890 - val_loss: 0.9467 - val_accuracy: 0.5644\n",
            "Epoch 4/7\n",
            "315/315 [==============================] - 24s 78ms/step - loss: 0.5984 - accuracy: 0.7619 - val_loss: 1.0470 - val_accuracy: 0.5526\n",
            "Epoch 5/7\n",
            "315/315 [==============================] - 23s 74ms/step - loss: 0.4600 - accuracy: 0.8261 - val_loss: 1.2213 - val_accuracy: 0.5485\n",
            "Epoch 6/7\n",
            "315/315 [==============================] - 25s 79ms/step - loss: 0.3463 - accuracy: 0.8773 - val_loss: 1.4197 - val_accuracy: 0.5331\n",
            "Epoch 7/7\n",
            "315/315 [==============================] - 24s 77ms/step - loss: 0.2632 - accuracy: 0.9100 - val_loss: 1.5901 - val_accuracy: 0.5215\n",
            "350/350 [==============================] - 2s 5ms/step - loss: 1.6054 - accuracy: 0.5211\n",
            "Test Loss (epochs=7, batch_size=128): 1.6054372787475586\n",
            "Test Accuracy (epochs=7, batch_size=128): 0.5211204290390015\n",
            "Training model with batch size = 128, epochs = 8\n",
            "Epoch 1/8\n",
            "315/315 [==============================] - 26s 80ms/step - loss: 0.9718 - accuracy: 0.5231 - val_loss: 0.8870 - val_accuracy: 0.5772\n",
            "Epoch 2/8\n",
            "315/315 [==============================] - 25s 80ms/step - loss: 0.8340 - accuracy: 0.6279 - val_loss: 0.8956 - val_accuracy: 0.5785\n",
            "Epoch 3/8\n",
            "315/315 [==============================] - 24s 75ms/step - loss: 0.7297 - accuracy: 0.6941 - val_loss: 0.9483 - val_accuracy: 0.5640\n",
            "Epoch 4/8\n",
            "315/315 [==============================] - 24s 77ms/step - loss: 0.5892 - accuracy: 0.7674 - val_loss: 1.0592 - val_accuracy: 0.5519\n",
            "Epoch 5/8\n",
            "315/315 [==============================] - 25s 79ms/step - loss: 0.4442 - accuracy: 0.8361 - val_loss: 1.2167 - val_accuracy: 0.5416\n",
            "Epoch 6/8\n",
            "315/315 [==============================] - 24s 75ms/step - loss: 0.3304 - accuracy: 0.8840 - val_loss: 1.4124 - val_accuracy: 0.5313\n",
            "Epoch 7/8\n",
            "315/315 [==============================] - 25s 78ms/step - loss: 0.2500 - accuracy: 0.9144 - val_loss: 1.6209 - val_accuracy: 0.5174\n",
            "Epoch 8/8\n",
            "315/315 [==============================] - 25s 79ms/step - loss: 0.1959 - accuracy: 0.9351 - val_loss: 1.7862 - val_accuracy: 0.5154\n",
            "350/350 [==============================] - 2s 5ms/step - loss: 1.7745 - accuracy: 0.5149\n",
            "Test Loss (epochs=8, batch_size=128): 1.774543046951294\n",
            "Test Accuracy (epochs=8, batch_size=128): 0.5148559212684631\n",
            "Training model with batch size = 128, epochs = 9\n",
            "Epoch 1/9\n",
            "315/315 [==============================] - 26s 78ms/step - loss: 0.9660 - accuracy: 0.5295 - val_loss: 0.8873 - val_accuracy: 0.5846\n",
            "Epoch 2/9\n",
            "315/315 [==============================] - 25s 81ms/step - loss: 0.8341 - accuracy: 0.6246 - val_loss: 0.8930 - val_accuracy: 0.5870\n",
            "Epoch 3/9\n",
            "315/315 [==============================] - 25s 80ms/step - loss: 0.7306 - accuracy: 0.6901 - val_loss: 0.9650 - val_accuracy: 0.5725\n",
            "Epoch 4/9\n",
            "315/315 [==============================] - 24s 77ms/step - loss: 0.5947 - accuracy: 0.7634 - val_loss: 1.0492 - val_accuracy: 0.5541\n",
            "Epoch 5/9\n",
            "315/315 [==============================] - 26s 82ms/step - loss: 0.4546 - accuracy: 0.8303 - val_loss: 1.2081 - val_accuracy: 0.5503\n",
            "Epoch 6/9\n",
            "315/315 [==============================] - 26s 83ms/step - loss: 0.3411 - accuracy: 0.8776 - val_loss: 1.3922 - val_accuracy: 0.5360\n",
            "Epoch 7/9\n",
            "315/315 [==============================] - 25s 79ms/step - loss: 0.2558 - accuracy: 0.9141 - val_loss: 1.6185 - val_accuracy: 0.5304\n",
            "Epoch 8/9\n",
            "315/315 [==============================] - 24s 77ms/step - loss: 0.1992 - accuracy: 0.9336 - val_loss: 1.8110 - val_accuracy: 0.5199\n",
            "Epoch 9/9\n",
            "315/315 [==============================] - 25s 81ms/step - loss: 0.1591 - accuracy: 0.9469 - val_loss: 2.0162 - val_accuracy: 0.5161\n",
            "350/350 [==============================] - 2s 5ms/step - loss: 2.0146 - accuracy: 0.5073\n",
            "Test Loss (epochs=9, batch_size=128): 2.014601707458496\n",
            "Test Accuracy (epochs=9, batch_size=128): 0.5073384642601013\n",
            "Training model with batch size = 128, epochs = 10\n",
            "Epoch 1/10\n",
            "315/315 [==============================] - 26s 80ms/step - loss: 0.9703 - accuracy: 0.5268 - val_loss: 0.8890 - val_accuracy: 0.5787\n",
            "Epoch 2/10\n",
            "315/315 [==============================] - 23s 74ms/step - loss: 0.8344 - accuracy: 0.6250 - val_loss: 0.8976 - val_accuracy: 0.5826\n",
            "Epoch 3/10\n",
            "315/315 [==============================] - 25s 79ms/step - loss: 0.7342 - accuracy: 0.6880 - val_loss: 0.9397 - val_accuracy: 0.5723\n",
            "Epoch 4/10\n",
            "315/315 [==============================] - 25s 79ms/step - loss: 0.5970 - accuracy: 0.7636 - val_loss: 1.0509 - val_accuracy: 0.5523\n",
            "Epoch 5/10\n",
            "315/315 [==============================] - 23s 74ms/step - loss: 0.4498 - accuracy: 0.8339 - val_loss: 1.2116 - val_accuracy: 0.5409\n",
            "Epoch 6/10\n",
            "315/315 [==============================] - 25s 78ms/step - loss: 0.3331 - accuracy: 0.8838 - val_loss: 1.3816 - val_accuracy: 0.5268\n",
            "Epoch 7/10\n",
            "315/315 [==============================] - 25s 78ms/step - loss: 0.2500 - accuracy: 0.9164 - val_loss: 1.5826 - val_accuracy: 0.5251\n",
            "Epoch 8/10\n",
            "315/315 [==============================] - 23s 74ms/step - loss: 0.1948 - accuracy: 0.9352 - val_loss: 1.7960 - val_accuracy: 0.5201\n",
            "Epoch 9/10\n",
            "315/315 [==============================] - 25s 79ms/step - loss: 0.1568 - accuracy: 0.9476 - val_loss: 1.9590 - val_accuracy: 0.5141\n",
            "Epoch 10/10\n",
            "315/315 [==============================] - 24s 77ms/step - loss: 0.1283 - accuracy: 0.9562 - val_loss: 2.1622 - val_accuracy: 0.5161\n",
            "350/350 [==============================] - 2s 7ms/step - loss: 2.2020 - accuracy: 0.5069\n",
            "Test Loss (epochs=10, batch_size=128): 2.202045440673828\n",
            "Test Accuracy (epochs=10, batch_size=128): 0.5068910121917725\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#The ouptuts for the different iterations are shown below"
      ],
      "metadata": {
        "id": "28cakTYtmvxC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Training model with batch size = 32, epochs = 1\n",
        "1257/1257 - val_loss: 0.8990 - val_accuracy: 0.5852\n",
        "---\n",
        "Epoch 2/2\n",
        "1257/1257 - val_loss: 0.9082 - val_accuracy: 0.5823\n",
        "---\n",
        "Epoch 3/3\n",
        "1257/1257 - val_loss: 1.0122 - val_accuracy: 0.5579\n",
        "---\n",
        "Epoch 4/4\n",
        "1257/1257 - val_loss: 1.2507 - val_accuracy: 0.5383\n",
        "---\n",
        "Epoch 5/5\n",
        "1257/1257 - val_loss: 1.5028 - val_accuracy: 0.5324\n",
        "---\n",
        "Epoch 6/6\n",
        "1257/1257 - val_loss: 1.8083 - val_accuracy: 0.5170\n",
        "---\n",
        "Epoch 7/7\n",
        "1257/1257 - val_loss: 2.0688 - val_accuracy: 0.5197\n",
        "---\n",
        "Epoch 8/8\n",
        "1257/1257 - val_loss: 2.4757 - val_accuracy: 0.5085\n",
        "---\n",
        "Epoch 9/9\n",
        "1257/1257 - val_loss: 2.6693 - val_accuracy: 0.5154\n",
        "---\n",
        "Epoch 10/10\n",
        "1257/1257 - val_loss: 2.9806 - val_accuracy: 0.5143\n",
        "---\n",
        "Training model with batch size = 64, epochs = 2\n",
        "---\n",
        "Epoch 2/2\n",
        "629/629 - val_loss: 0.8993 - val_accuracy: 0.5785\n",
        "---\n",
        "Epoch 3/3\n",
        "629/629 - val_loss: 0.9792 - val_accuracy: 0.5579\n",
        "---\n",
        "Epoch 4/4\n",
        "629/629 - val_loss: 1.1611 - val_accuracy: 0.5479\n",
        "---\n",
        "Epoch 5/5\n",
        "629/629 - val_loss: 1.3398 - val_accuracy: 0.5365\n",
        "---\n",
        "Epoch 6/6\n",
        "629/629 - val_loss: 1.6142 - val_accuracy: 0.5219\n",
        "---\n",
        "Epoch 7/7\n",
        "629/629 - val_loss: 1.8902 - val_accuracy: 0.5186\n",
        "---\n",
        "Epoch 8/8\n",
        "629/629 - val_loss: 2.1048 - val_accuracy: 0.5174\n",
        "---\n",
        "Epoch 9/9\n",
        "629/629 - val_loss: 2.3445 - val_accuracy: 0.5067\n",
        "---\n",
        "Epoch 10/10\n",
        "629/629 - val_loss: 2.5957 - val_accuracy: 0.5105\n",
        "---\n",
        "Test Accuracy (epochs=2, batch_size=128): 0.5784857869148254\n",
        "Training model with batch size = 128, epochs = 3\n",
        "---\n",
        "Epoch 3/3\n",
        "315/315 - val_loss: 0.9566 - val_accuracy: 0.5631\n",
        "---\n",
        "Epoch 4/4\n",
        "315/315 - val_loss: 1.0425 - val_accuracy: 0.5488\n",
        "---\n",
        "Epoch 5/5\n",
        "315/315 - val_loss: 1.1965 - val_accuracy: 0.5353\n",
        "---\n",
        "Epoch 6/6\n",
        "315/315 - val_loss: 1.3681 - val_accuracy: 0.5327\n",
        "---\n",
        "Epoch 7/7\n",
        "315/315 - val_loss: 1.5901 - val_accuracy: 0.5215\n",
        "---\n",
        "Epoch 8/8\n",
        "315/315 - val_loss: 1.7862 - val_accuracy: 0.5154\n",
        "---\n",
        "Epoch 9/9\n",
        "315/315 - val_loss: 2.0162 - val_accuracy: 0.5161\n",
        "---\n",
        "Epoch 10/10\n",
        "315/315 - val_loss: 2.1622 - val_accuracy: 0.5161\n",
        "---\n",
        "Test Loss (epochs=10, batch_size=128): 2.202045440673828\n",
        "---\n",
        "Epoch 2/2\n",
        "1257/1257 - val_loss: 0.9082 - val_accuracy: 0.5823\n",
        "---\n",
        "Epoch 3/3\n",
        "1257/1257 - val_loss: 1.0122 - val_accuracy: 0.5579\n",
        "---\n",
        "Epoch 4/4\n",
        "1257/1257 - val_loss: 1.2507 - val_accuracy: 0.5383\n",
        "---\n",
        "Epoch 5/5\n",
        "1257/1257 - val_loss: 1.5028 - val_accuracy: 0.5324\n",
        "---\n",
        "Epoch 6/6\n",
        "1257/1257 - val_loss: 1.8083 - val_accuracy: 0.5170\n",
        "---\n",
        "Epoch 7/7\n",
        "1257/1257 - val_loss: 2.0688 - val_accuracy: 0.5197\n",
        "---\n",
        "Epoch 8/8\n",
        "1257/1257 - val_loss: 2.4757 - val_accuracy: 0.5085\n",
        "---\n",
        "Epoch 9/9\n",
        "1257/1257 - val_loss: 2.6693 - val_accuracy: 0.5154\n",
        "---\n",
        "Epoch 10/10\n",
        "1257/1257 - val_loss: 2.9806 - val_accuracy: 0.5143\n"
      ],
      "metadata": {
        "id": "pERKiExo4TfO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Training model with batch size = 64, epochs = 1 - val_loss: 0.9967 - val_accuracy: 0.5742\n",
        "\n",
        "---\n",
        "Epoch 1/2 - val_loss: 1.0030 - val_accuracy: 0.5717\n",
        "---\n",
        "Epoch 2/2- val_loss: 1.0048 - val_accuracy: 0.5736\n",
        "---\n",
        "Epoch 3/3- val_loss: 1.0159 - val_accuracy: 0.5713\n",
        "---\n",
        "Epoch 4/4 - val_loss: 1.0430 - val_accuracy: 0.5747\n",
        "---\n",
        "Epoch 5/5 - val_loss: 1.0548 - val_accuracy: 0.5715\n",
        "---\n",
        "Epoch 6/6 - val_loss: 1.0853 - val_accuracy: 0.5704\n",
        "---\n",
        "Epoch 7/7 - val_loss: 1.1043 - val_accuracy: 0.5672\n",
        "---\n",
        "Epoch 8/8 - val_loss: 1.1107 - val_accuracy: 0.5688\n",
        "---\n",
        "Epoch 9/9 - val_loss: 1.1271 - val_accuracy: 0.5611\n",
        "---\n",
        "Epoch 10/10 - val_loss: 1.1398 - val_accuracy: 0.5651\n",
        "---\n"
      ],
      "metadata": {
        "id": "p-5BmAXlfsyJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Training model with batch size = 128, epochs = 1 - val_loss: 0.9952 - val_accuracy: 0.5721\n",
        "---\n",
        "Epoch 1/2 - val_loss: 0.9957 - val_accuracy: 0.5721\n",
        "---\n",
        "Epoch 2/2 - val_loss: 0.9969 - val_accuracy: 0.5776\n",
        "---\n",
        "Epoch 3/3 - val_loss: 1.0125 - val_accuracy: 0.5777\n",
        "---\n",
        "Epoch 4/4 - val_loss: 1.0340 - val_accuracy: 0.5735\n",
        "---\n",
        "Epoch 5/5 - val_loss: 1.0591 - val_accuracy: 0.5675\n",
        "---\n",
        "Epoch 6/6 - val_loss: 1.0886 - val_accuracy: 0.5697\n",
        "---\n",
        "Epoch 7/7 - val_loss: 1.1018 - val_accuracy: 0.5704\n",
        "---\n",
        "Epoch 8/8 - val_loss: 1.1190 - val_accuracy: 0.5684\n",
        "---\n",
        "Epoch 9/9 - val_loss: 1.1361 - val_accuracy: 0.5678\n",
        "---\n",
        "Epoch 10/10 - val_loss: 1.1496 - val_accuracy: 0.5654\n",
        "---\n",
        "Test Loss (epochs=10, batch_size=128): 1.1456750631332397\n",
        "Test Accuracy (epochs=10, batch_size=128): 0.5665375590324402"
      ],
      "metadata": {
        "id": "yM-vfWKNG3Uh"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Performing Hyper Parameter tuning for the above model using: -\n",
        "\n",
        "\n",
        "*   5 random iterations of hyperparameter combinations\n",
        "*   3 fold cross validation\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "meCiOXD3gcHi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the CNN model function\n",
        "def create_cnn_model(num_filters=128, dense_size=128):\n",
        "    model = Sequential()\n",
        "    model.add(Embedding(input_dim=len(word_index) + 1, output_dim=embedding_dim, input_length=max_sequence_length))\n",
        "    model.add(Conv1D(num_filters, 5, activation='relu'))\n",
        "    model.add(GlobalMaxPooling1D())\n",
        "    model.add(Dense(dense_size, activation='relu'))\n",
        "    model.add(Dense(4, activation='softmax'))  # Four units for four classes, using softmax activation\n",
        "\n",
        "    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "    return model\n",
        "\n",
        "# Create KerasClassifier for RandomizedSearchCV\n",
        "model = KerasClassifier(build_fn=create_cnn_model, verbose=0)\n",
        "\n",
        "# Define hyperparameter grid for Random Search\n",
        "param_grid = {\n",
        "    'num_filters': [64, 128, 256],\n",
        "    'dense_size': [64, 128, 256]\n",
        "}\n",
        "\n",
        "# Perform Random Search with 3-fold cross-validation\n",
        "random_search = RandomizedSearchCV(model, param_distributions=param_grid, n_iter=5, cv=3, verbose=2)\n",
        "random_search_result = random_search.fit(padded_sequences, one_hot_labels)\n",
        "\n",
        "# Print the best hyperparameters and their corresponding accuracy\n",
        "print(\"Best Hyperparameters: \", random_search_result.best_params_)\n",
        "print(\"Best Accuracy: \", random_search_result.best_score_)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2VXGt8u0dKam",
        "outputId": "e9adda36-3401-4308-f4d9-186212b91a4c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fitting 3 folds for each of 5 candidates, totalling 15 fits\n",
            "[CV] END ....................dense_size=256, num_filters=128; total time= 1.4min\n",
            "[CV] END ....................dense_size=256, num_filters=128; total time=  57.3s\n",
            "[CV] END ....................dense_size=256, num_filters=128; total time= 1.4min\n",
            "[CV] END ....................dense_size=128, num_filters=256; total time= 1.5min\n",
            "[CV] END ....................dense_size=128, num_filters=256; total time= 1.2min\n",
            "[CV] END ....................dense_size=128, num_filters=256; total time= 1.5min\n",
            "[CV] END .....................dense_size=128, num_filters=64; total time= 1.4min\n",
            "[CV] END .....................dense_size=128, num_filters=64; total time=  49.0s\n",
            "[CV] END .....................dense_size=128, num_filters=64; total time=  47.6s\n",
            "[CV] END .....................dense_size=64, num_filters=128; total time= 1.4min\n",
            "[CV] END .....................dense_size=64, num_filters=128; total time=  53.5s\n",
            "[CV] END .....................dense_size=64, num_filters=128; total time= 1.4min\n",
            "[CV] END ......................dense_size=64, num_filters=64; total time= 1.4min\n",
            "[CV] END ......................dense_size=64, num_filters=64; total time= 1.4min\n",
            "[CV] END ......................dense_size=64, num_filters=64; total time=  48.7s\n",
            "Best Hyperparameters:  {'num_filters': 64, 'dense_size': 64}\n",
            "Best Accuracy:  0.5764838655789694\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The following are the best hyperparameters obtained\n",
        "Fitting 3 folds for each of 5 candidates, totalling 15 fits\n",
        "\n",
        "---\n",
        "[CV] END ....................dense_size=128, num_filters=128; total time= 4.6min\n",
        "---\n",
        "[CV] END ....................dense_size=128, num_filters=128; total time= 4.6min\n",
        "---\n",
        "[CV] END ....................dense_size=128, num_filters=128; total time= 4.5min\n",
        "---\n",
        "[CV] END .....................dense_size=256, num_filters=64; total time= 3.3min\n",
        "---\n",
        "[CV] END .....................dense_size=256, num_filters=64; total time= 3.2min\n",
        "---\n",
        "[CV] END .....................dense_size=256, num_filters=64; total time= 3.6min\n",
        "---\n",
        "[CV] END ....................dense_size=256, num_filters=256; total time= 4.6min\n",
        "---\n",
        "[CV] END ....................dense_size=256, num_filters=256; total time= 4.6min\n",
        "---\n",
        "[CV] END ....................dense_size=256, num_filters=256; total time= 4.6min\n",
        "---\n",
        "[CV] END .....................dense_size=64, num_filters=256; total time= 4.4min\n",
        "---\n",
        "[CV] END .....................dense_size=64, num_filters=256; total time= 4.7min\n",
        "---\n",
        "[CV] END .....................dense_size=64, num_filters=256; total time= 4.6min\n",
        "---\n",
        "[CV] END ......................dense_size=64, num_filters=64; total time= 3.5min\n",
        "---\n",
        "[CV] END ......................dense_size=64, num_filters=64; total time= 3.6min\n",
        "---\n",
        "[CV] END ......................dense_size=64, num_filters=64; total time= 3.2min\n",
        "---\n",
        "Best Hyperparameters:  {'num_filters': 64, 'dense_size': 64}\n",
        "Best Accuracy:  0.5702888170878092\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "jw2io7b8RN1l"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Including the best num_filters and dense_size of 64\n",
        "from sklearn.metrics import confusion_matrix\n",
        "\n",
        "# Splitting data into training and test sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(padded_sequences, one_hot_labels, test_size=0.2, random_state=42)\n",
        "\n",
        "best_model = create_cnn_model(num_filters=64, dense_size=64)  # Use the best parameters\n",
        "\n",
        "# Training the model on the training set\n",
        "best_model.fit(X_train, y_train, epochs=10, batch_size=128, validation_split=0.1, verbose=1)\n",
        "\n",
        "# Making predictions on the test set\n",
        "y_pred_probs = best_model.predict(X_test)\n",
        "y_pred = np.argmax(y_pred_probs, axis=1)  # Convert predicted probabilities to class labels\n",
        "\n",
        "# Converting the one-hot encoded test labels back to integer labels\n",
        "y_test_labels = np.argmax(y_test, axis=1)\n",
        "\n",
        "# Creating the confusion matrix\n",
        "conf_matrix = confusion_matrix(y_test_labels, y_pred)\n",
        "\n",
        "print(\"Confusion Matrix:\")\n",
        "print(conf_matrix)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vAAtNGrRyNsd",
        "outputId": "52e27609-51be-47de-fb9e-055c704cf913"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "315/315 [==============================] - 24s 70ms/step - loss: 0.9802 - accuracy: 0.5175 - val_loss: 0.8850 - val_accuracy: 0.5810\n",
            "Epoch 2/10\n",
            "315/315 [==============================] - 20s 63ms/step - loss: 0.8349 - accuracy: 0.6265 - val_loss: 0.9022 - val_accuracy: 0.5819\n",
            "Epoch 3/10\n",
            "315/315 [==============================] - 20s 64ms/step - loss: 0.7114 - accuracy: 0.7031 - val_loss: 0.9595 - val_accuracy: 0.5709\n",
            "Epoch 4/10\n",
            "315/315 [==============================] - 19s 60ms/step - loss: 0.5258 - accuracy: 0.7982 - val_loss: 1.1457 - val_accuracy: 0.5559\n",
            "Epoch 5/10\n",
            "315/315 [==============================] - 19s 60ms/step - loss: 0.3504 - accuracy: 0.8731 - val_loss: 1.4020 - val_accuracy: 0.5327\n",
            "Epoch 6/10\n",
            "315/315 [==============================] - 21s 67ms/step - loss: 0.2294 - accuracy: 0.9191 - val_loss: 1.7140 - val_accuracy: 0.5324\n",
            "Epoch 7/10\n",
            "315/315 [==============================] - 19s 61ms/step - loss: 0.1590 - accuracy: 0.9451 - val_loss: 2.0284 - val_accuracy: 0.5103\n",
            "Epoch 8/10\n",
            "315/315 [==============================] - 20s 63ms/step - loss: 0.1185 - accuracy: 0.9590 - val_loss: 2.3276 - val_accuracy: 0.5085\n",
            "Epoch 9/10\n",
            "315/315 [==============================] - 21s 66ms/step - loss: 0.0911 - accuracy: 0.9684 - val_loss: 2.6641 - val_accuracy: 0.5141\n",
            "Epoch 10/10\n",
            "315/315 [==============================] - 19s 60ms/step - loss: 0.0757 - accuracy: 0.9732 - val_loss: 2.9271 - val_accuracy: 0.5107\n",
            "350/350 [==============================] - 1s 3ms/step\n",
            "Confusion Matrix:\n",
            "[[1399  711 1025]\n",
            " [ 806 1020 1180]\n",
            " [ 863  943 3227]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Create the confusion matrix\n",
        "conf_matrix = confusion_matrix(y_test_labels, y_pred)\n",
        "\n",
        "# Plotting the confusion matrix using seaborn heatmap\n",
        "plt.figure(figsize=(8, 6))\n",
        "sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues', xticklabels=['Class 0', 'Class 1', 'Class 2'],\n",
        "            yticklabels=['Class 0', 'Class 1', 'Class 2'])\n",
        "plt.xlabel('Predicted Labels')\n",
        "plt.ylabel('True Labels')\n",
        "plt.title('Confusion Matrix')\n",
        "plt.show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 235
        },
        "id": "fKRftGpLeE_1",
        "outputId": "e4fccd61-13b4-4e87-932e-f115618ccb4c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-4-dabe945289be>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Create the confusion matrix\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mconf_matrix\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconfusion_matrix\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_test_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# Plot the confusion matrix using seaborn heatmap\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfigure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfigsize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m8\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m6\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'y_test_labels' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "True Positives (TP):\n",
        "\n",
        "Class 0: 1399 (Correctly predicted instances of class 0 - negative)\n",
        "---\n",
        "Class 1: 1020 (Correctly predicted instances of class 1 - neutral)\n",
        "---\n",
        "Class 2: 3227 (Correctly predicted instances of class 2 - positive)\n",
        "---\n",
        "\n",
        "False Positives (FP):\n",
        "\n",
        "Class 0: 806 (Instances that belong to neutral but were predicted as negative)\n",
        "---\n",
        "Class 1: 711 (Instances that belong to negative but were predicted as neutral)\n",
        "---\n",
        "Class 2: 943 (Instances that belong to negative but were predicted as positive)\n",
        "---\n",
        "\n",
        "False Negatives (FN):\n",
        "\n",
        "Class 0: 1025 (Instances that belong to negative but were predicted as neutral or positive)\n",
        "---\n",
        "Class 1: 1180 (Instances that belong to neutral but were predicted as positive or negative)\n",
        "---\n",
        "Class 2: 863 (Instances that belong to positive but were predicted as neutral or positive)\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "CMBvLDEEMm8w"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Displaying the performace metrics**"
      ],
      "metadata": {
        "id": "vatcxlfvQPEb"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Precision -0.6656\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "Recall - 0.6102\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "F1 Score - 0.6377\n"
      ],
      "metadata": {
        "id": "Xi8KNoTFWtDP"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ArhSGjC9XCuv"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}